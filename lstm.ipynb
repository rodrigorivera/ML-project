{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": " lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pHLIYpIedrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d89_GfEcrjEI",
        "colab_type": "code",
        "outputId": "1cd5316f-a9b3-4528-befe-922ce3abd84d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "with open('plain_ts2.pickle', 'rb') as handle:\n",
        "    time_series = pickle.load(handle)\n",
        "\n",
        "print(len(time_series))\n",
        "print(time_series[0].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30490\n",
            "(1012,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSZD_bTpoob9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = [ts[:-50] for ts in time_series]\n",
        "df_val = [ts[-50:] for ts in time_series]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw_KsBhNedtp",
        "colab_type": "text"
      },
      "source": [
        "### Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jpKjNPbedts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform_data(arr, seq_len):\n",
        "    step = seq_len // 2\n",
        "    x, y = [], []\n",
        "    for ts_idx, ts in enumerate(arr):\n",
        "        if ts_idx % 3000 == 0: print('ts_idx =', ts_idx)\n",
        "        len_ts = len(ts)\n",
        "        n_seq = (len_ts - 1) // step - 1\n",
        "        offset = len_ts - 1 - (n_seq + 1) * step\n",
        "        for i in range(0, len_ts - offset - seq_len, step):\n",
        "            x_i = ts[offset + i : offset + i + seq_len]\n",
        "            y_i = ts[offset + i + 1 : offset + i + seq_len + 1]\n",
        "            x.append(x_i)\n",
        "            y.append(y_i)\n",
        "    \n",
        "    x_arr = np.vstack(x)\n",
        "    del x\n",
        "    y_arr = np.vstack(y)\n",
        "    del y\n",
        "    x_var = Variable(torch.from_numpy(x_arr).float())\n",
        "    y_var = Variable(torch.from_numpy(y_arr).float())\n",
        "    return x_var, y_var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC97NNXnedt4",
        "colab_type": "code",
        "outputId": "22eb6f2f-0689-4748-c8d2-8d3d9cfba949",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "seq_len = 32\n",
        "\n",
        "x_train, y_train = transform_data(df_train, seq_len)\n",
        "x_val, y_val = transform_data(df_val, seq_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ts_idx = 0\n",
            "ts_idx = 3000\n",
            "ts_idx = 6000\n",
            "ts_idx = 9000\n",
            "ts_idx = 12000\n",
            "ts_idx = 15000\n",
            "ts_idx = 18000\n",
            "ts_idx = 21000\n",
            "ts_idx = 24000\n",
            "ts_idx = 27000\n",
            "ts_idx = 30000\n",
            "ts_idx = 0\n",
            "ts_idx = 3000\n",
            "ts_idx = 6000\n",
            "ts_idx = 9000\n",
            "ts_idx = 12000\n",
            "ts_idx = 15000\n",
            "ts_idx = 18000\n",
            "ts_idx = 21000\n",
            "ts_idx = 24000\n",
            "ts_idx = 27000\n",
            "ts_idx = 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuiLKldieduL",
        "colab_type": "text"
      },
      "source": [
        "## Long Short Term Memory Neural Network\n",
        "Part of code is taken from here: <a href='https://romanorac.github.io/machine/learning/2019/09/27/time-series-prediction-with-lstm.html'>LSTM for time series prediction</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izP5aLOeeduN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, device):\n",
        "        super(Model, self).__init__()\n",
        "        self.device = device\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.lstm = nn.LSTMCell(self.input_size, self.hidden_size)\n",
        "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input_, future=0, y=None):\n",
        "        # input dim = (batch, seq_len, input_size)\n",
        "        outputs = []\n",
        "        hidden = []\n",
        "\n",
        "        # reset the state of LSTM\n",
        "        # the state is kept till the end of the sequence\n",
        "        h_t = torch.zeros(input_.size(0), self.hidden_size, dtype=torch.float32, device=self.device)\n",
        "        c_t = torch.zeros(input_.size(0), self.hidden_size, dtype=torch.float32, device=self.device)\n",
        "\n",
        "        for i, input_t in enumerate(input_.chunk(input_.size(1), dim=1)):\n",
        "            h_t, c_t = self.lstm(input_t, (h_t, c_t))\n",
        "            output = self.linear(h_t)\n",
        "            outputs += [output]\n",
        "            hidden += [h_t]\n",
        "\n",
        "        for i in range(future):\n",
        "            if y is not None and random.random() > 0.5:\n",
        "                output = y[:, [i]]  # teacher forcing\n",
        "            h_t, c_t = self.lstm(output, (h_t, c_t))\n",
        "            output = self.linear(h_t)\n",
        "            outputs += [output]\n",
        "            hidden += [h_t]\n",
        "        outputs = torch.stack(outputs, 1).squeeze(2)\n",
        "        return outputs, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cRTU38XH1sF",
        "colab_type": "code",
        "outputId": "cc06cbfc-da95-4f29-a910-f31ed8d49810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwSiIqjCeduV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Optimization:\n",
        "    \"\"\" A helper class to train, test and diagnose the LSTM\"\"\"\n",
        "\n",
        "    def __init__(self, model, loss_fn, optimizer, scheduler, device):\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.futures = []\n",
        "        self.device = device\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_batch_data(x, y, batch_size):\n",
        "        for batch, i in enumerate(range(0, len(x) - batch_size + 1, batch_size)): ### + 1 ???\n",
        "            x_batch = x[i : i + batch_size]\n",
        "            y_batch = y[i : i + batch_size]\n",
        "            yield x_batch, y_batch, batch\n",
        "\n",
        "    def train(\n",
        "        self,\n",
        "        x_train,\n",
        "        y_train,\n",
        "        x_val=None,\n",
        "        y_val=None,\n",
        "        batch_size=32,\n",
        "        n_epochs=15,\n",
        "        do_teacher_forcing=None,\n",
        "        output_path=None,\n",
        "    ):\n",
        "        seq_len = x_train.shape[1]\n",
        "        self.model = self.model.to(self.device)\n",
        "        for epoch in range(n_epochs):\n",
        "            start_time = time.time()\n",
        "            self.futures = []\n",
        "\n",
        "            train_loss = 0\n",
        "            self.model.train()\n",
        "            for x_batch, y_batch, batch in self.generate_batch_data(x_train, y_train, batch_size):\n",
        "                x_batch, y_batch = x_batch.to(self.device), y_batch.to(self.device)\n",
        "                if batch % 2500 == 0:\n",
        "                    print('batch =', batch, 'time =', int(time.time() - start_time))\n",
        "                y_pred = self._predict(x_batch, y_batch, seq_len, do_teacher_forcing)\n",
        "                self.optimizer.zero_grad()\n",
        "                loss = self.loss_fn(y_pred, y_batch)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                train_loss += loss.item()\n",
        "            self.scheduler.step()\n",
        "            train_loss /= batch\n",
        "            self.train_losses.append(train_loss)\n",
        "\n",
        "            self._validation(x_val, y_val, batch_size)\n",
        "\n",
        "            if output_path and\\\n",
        "             (epoch == 0 or self.val_losses[-1] < self.val_losses[-2]):\n",
        "                torch.save(self.model.state_dict(), output_path)\n",
        "            \n",
        "            elapsed = time.time() - start_time\n",
        "            print(\n",
        "                \"Epoch %d Train loss: %.2f. Validation loss: %.2f. Avg future: %.2f. Elapsed time: %.2fs.\"\n",
        "                % (epoch + 1, train_loss, self.val_losses[-1], np.average(self.futures), elapsed)\n",
        "            )\n",
        "\n",
        "    def _predict(self, x_batch, y_batch, seq_len, do_teacher_forcing):\n",
        "        if do_teacher_forcing:\n",
        "            future = random.randint(1, int(seq_len) // 2)\n",
        "            limit = x_batch.size(1) - future\n",
        "            y_pred, _ = self.model(x_batch[:, :limit], future=future, y=y_batch[:, limit:])\n",
        "        else:\n",
        "            future = 0\n",
        "            # print(self.device)\n",
        "            y_pred, _ = self.model(x_batch)\n",
        "        self.futures.append(future)\n",
        "        return y_pred\n",
        "\n",
        "    def _validation(self, x_val, y_val, batch_size):\n",
        "        self.model.eval()\n",
        "        if x_val is None or y_val is None:\n",
        "            return\n",
        "        with torch.no_grad():\n",
        "            val_loss = 0\n",
        "            batch = 1\n",
        "            for x_batch, y_batch, batch in self.generate_batch_data(x_val, y_val, batch_size):\n",
        "                x_batch, y_batch = x_batch.to(self.device), y_batch.to(self.device)\n",
        "                y_pred, _ = self.model(x_batch)\n",
        "                loss = self.loss_fn(y_pred, y_batch)\n",
        "                val_loss += loss.item()\n",
        "            val_loss /= batch\n",
        "            self.val_losses.append(val_loss)\n",
        "\n",
        "    def evaluate(self, x_test, y_test, batch_size, future=1):\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            test_loss = 0\n",
        "            actual, predicted = [], []\n",
        "            for x_batch, y_batch, batch in self.generate_batch_data(x_test, y_test, batch_size):\n",
        "                x_batch, y_batch = x_batch.to(self.device), y_batch.to(self.device)\n",
        "                y_pred, _ = self.model(x_batch, future=future)\n",
        "                y_pred = (\n",
        "                    y_pred[:, -len(y_batch) :] if y_pred.shape[1] > y_batch.shape[1] else y_pred\n",
        "                )\n",
        "                loss = self.loss_fn(y_pred, y_batch)\n",
        "                test_loss += loss.item()\n",
        "                actual += torch.squeeze(y_batch[:, -1]).data.cpu().numpy().tolist()\n",
        "                predicted += torch.squeeze(y_pred[:, -1]).data.cpu().numpy().tolist()\n",
        "            test_loss /= batch\n",
        "            return actual, predicted, test_loss\n",
        "\n",
        "    def plot_losses(self):\n",
        "        plt.plot(self.train_losses, label=\"Training loss\")\n",
        "        plt.plot(self.val_losses, label=\"Validation loss\")\n",
        "        plt.legend()\n",
        "        plt.title(\"Losses\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWJe73mEedud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sequence(scaler, model, x_sample, future=58):\n",
        "    \"\"\" Generate future values for x_sample with the model \"\"\"\n",
        "    y_pred_tensor = model(x_sample, future=future)\n",
        "    y_pred = y_pred_tensor.cpu().tolist()\n",
        "    y_pred = scaler.inverse_transform(y_pred)\n",
        "    return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whsiDkYTedui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_dataframe(actual, predicted):\n",
        "    return pd.DataFrame({\"actual\": actual, \"predicted\": predicted})\n",
        "\n",
        "\n",
        "def inverse_transform(scalar, df, columns):\n",
        "    for col in columns:\n",
        "        df[col] = scaler.inverse_transform(df[col])\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2dpOF9_edut",
        "colab_type": "text"
      },
      "source": [
        "## Training the LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjAT7nzleduu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1 = Model(input_size=1, hidden_size=16, output_size=1, device=device)\n",
        "loss_fn_1 = nn.MSELoss().cuda()\n",
        "optimizer_1 = optim.Adam(model_1.parameters(), lr=1e-3)\n",
        "scheduler_1 = optim.lr_scheduler.StepLR(optimizer_1, step_size=5, gamma=0.1)\n",
        "optimization_1 = Optimization(model_1, loss_fn_1, optimizer_1, scheduler_1, device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_9wupcTedu0",
        "colab_type": "code",
        "outputId": "dc7f6838-ec2b-4f19-9788-f7e84e7142d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "optimization_1.train(x_train, y_train, x_val, y_val, batch_size=256, do_teacher_forcing=False, n_epochs=15, output_path='model_weights_no_shuffle.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch = 0 time = 0\n",
            "batch = 2500 time = 44\n",
            "batch = 5000 time = 88\n",
            "batch = 7500 time = 132\n",
            "batch = 10000 time = 176\n",
            "Epoch 1 Train loss: 10.74. Validation loss: 5.75. Avg future: 0.00. Elapsed time: 189.79s.\n",
            "batch = 0 time = 0\n",
            "batch = 2500 time = 44\n",
            "batch = 5000 time = 88\n",
            "batch = 7500 time = 132\n",
            "batch = 10000 time = 177\n",
            "Epoch 2 Train loss: 8.54. Validation loss: 5.14. Avg future: 0.00. Elapsed time: 190.44s.\n",
            "batch = 0 time = 0\n",
            "batch = 2500 time = 44\n",
            "batch = 5000 time = 88\n",
            "batch = 7500 time = 133\n",
            "batch = 10000 time = 177\n",
            "Epoch 3 Train loss: 7.85. Validation loss: 4.89. Avg future: 0.00. Elapsed time: 190.67s.\n",
            "batch = 0 time = 0\n",
            "batch = 2500 time = 44\n",
            "batch = 5000 time = 88\n",
            "batch = 7500 time = 132\n",
            "batch = 10000 time = 177\n",
            "Epoch 4 Train loss: 7.48. Validation loss: 4.74. Avg future: 0.00. Elapsed time: 190.49s.\n",
            "batch = 0 time = 0\n",
            "batch = 2500 time = 44\n",
            "batch = 5000 time = 88\n",
            "batch = 7500 time = 132\n",
            "batch = 10000 time = 176\n",
            "Epoch 5 Train loss: 7.23. Validation loss: 4.65. Avg future: 0.00. Elapsed time: 189.85s.\n",
            "batch = 0 time = 0\n",
            "batch = 2500 time = 44\n",
            "batch = 5000 time = 88\n",
            "batch = 7500 time = 132\n",
            "batch = 10000 time = 176\n",
            "Epoch 6 Train loss: 7.10. Validation loss: 4.60. Avg future: 0.00. Elapsed time: 189.71s.\n",
            "batch = 0 time = 0\n",
            "batch = 2500 time = 44\n",
            "batch = 5000 time = 88\n",
            "batch = 7500 time = 132\n",
            "batch = 10000 time = 177\n",
            "Epoch 7 Train loss: 7.07. Validation loss: 4.59. Avg future: 0.00. Elapsed time: 190.54s.\n",
            "batch = 0 time = 0\n",
            "batch = 2500 time = 44\n",
            "batch = 5000 time = 88\n",
            "batch = 7500 time = 133\n",
            "batch = 10000 time = 177\n",
            "Epoch 8 Train loss: 7.06. Validation loss: 4.59. Avg future: 0.00. Elapsed time: 190.52s.\n",
            "batch = 0 time = 0\n",
            "batch = 2500 time = 44\n",
            "batch = 5000 time = 88\n",
            "batch = 7500 time = 133\n",
            "batch = 10000 time = 177\n",
            "Epoch 9 Train loss: 7.04. Validation loss: 4.58. Avg future: 0.00. Elapsed time: 190.26s.\n",
            "batch = 0 time = 0\n",
            "batch = 2500 time = 44\n",
            "batch = 5000 time = 88\n",
            "batch = 7500 time = 132\n",
            "batch = 10000 time = 176\n",
            "Epoch 10 Train loss: 7.02. Validation loss: 4.57. Avg future: 0.00. Elapsed time: 189.31s.\n",
            "batch = 0 time = 0\n",
            "batch = 2500 time = 44\n",
            "batch = 5000 time = 88\n",
            "batch = 7500 time = 132\n",
            "batch = 10000 time = 176\n",
            "Epoch 11 Train loss: 7.03. Validation loss: 4.55. Avg future: 0.00. Elapsed time: 189.10s.\n",
            "batch = 0 time = 0\n",
            "batch = 2500 time = 44\n",
            "batch = 5000 time = 88\n",
            "batch = 7500 time = 132\n",
            "batch = 10000 time = 175\n",
            "Epoch 12 Train loss: 7.02. Validation loss: 4.55. Avg future: 0.00. Elapsed time: 188.58s.\n",
            "batch = 0 time = 0\n",
            "batch = 2500 time = 44\n",
            "batch = 5000 time = 88\n",
            "batch = 7500 time = 132\n",
            "batch = 10000 time = 176\n",
            "Epoch 13 Train loss: 7.01. Validation loss: 4.55. Avg future: 0.00. Elapsed time: 190.08s.\n",
            "batch = 0 time = 0\n",
            "batch = 2500 time = 44\n",
            "batch = 5000 time = 88\n",
            "batch = 7500 time = 133\n",
            "batch = 10000 time = 178\n",
            "Epoch 14 Train loss: 7.01. Validation loss: 4.55. Avg future: 0.00. Elapsed time: 191.32s.\n",
            "batch = 0 time = 0\n",
            "batch = 2500 time = 44\n",
            "batch = 5000 time = 88\n",
            "batch = 7500 time = 133\n",
            "batch = 10000 time = 178\n",
            "Epoch 15 Train loss: 7.01. Validation loss: 4.54. Avg future: 0.00. Elapsed time: 191.40s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5KHL4xHmhMg",
        "colab_type": "code",
        "outputId": "f1f11438-a1ed-4120-d26a-9cfaa1efc630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "preds = np.zeros((len(df_val), 59), dtype='int')\n",
        "for i in range(0, len(df_val), 200):\n",
        "    batch = np.vstack(df_val[i : i + 200])[:, -32:]\n",
        "    batch_var = Variable(torch.from_numpy(batch).float()).to(device)\n",
        "    if i % 5000 == 0:\n",
        "        print('i =', i)\n",
        "    y_pred, _ = model_1(batch_var, future=27) # y_pred: (200, 59)\n",
        "    preds[i : i + 200] = np.around(y_pred.detach().cpu().numpy()).astype('int')\n",
        "\n",
        "batch = np.vstack(df_val[-90:])[:, -32:]\n",
        "batch_var = Variable(torch.from_numpy(batch).float()).to(device)\n",
        "y_pred, _ = model_1(batch_var, future=27)\n",
        "preds[-90:] = np.around(y_pred.detach().cpu().numpy()).astype('int')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i = 0\n",
            "i = 5000\n",
            "i = 10000\n",
            "i = 15000\n",
            "i = 20000\n",
            "i = 25000\n",
            "i = 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6Tv5UK1uDP7",
        "colab_type": "code",
        "outputId": "2633b2e1-3ecb-4946-d238-ed9299e5d414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "ss = pd.read_csv('sample_submission.csv')\n",
        "ss.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>F5</th>\n",
              "      <th>F6</th>\n",
              "      <th>F7</th>\n",
              "      <th>F8</th>\n",
              "      <th>F9</th>\n",
              "      <th>F10</th>\n",
              "      <th>F11</th>\n",
              "      <th>F12</th>\n",
              "      <th>F13</th>\n",
              "      <th>F14</th>\n",
              "      <th>F15</th>\n",
              "      <th>F16</th>\n",
              "      <th>F17</th>\n",
              "      <th>F18</th>\n",
              "      <th>F19</th>\n",
              "      <th>F20</th>\n",
              "      <th>F21</th>\n",
              "      <th>F22</th>\n",
              "      <th>F23</th>\n",
              "      <th>F24</th>\n",
              "      <th>F25</th>\n",
              "      <th>F26</th>\n",
              "      <th>F27</th>\n",
              "      <th>F28</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              id  F1  F2  F3  F4  ...  F24  F25  F26  F27  F28\n",
              "0  HOBBIES_1_001_CA_1_validation   0   0   0   0  ...    0    0    0    0    0\n",
              "1  HOBBIES_1_002_CA_1_validation   0   0   0   0  ...    0    0    0    0    0\n",
              "2  HOBBIES_1_003_CA_1_validation   0   0   0   0  ...    0    0    0    0    0\n",
              "3  HOBBIES_1_004_CA_1_validation   0   0   0   0  ...    0    0    0    0    0\n",
              "4  HOBBIES_1_005_CA_1_validation   0   0   0   0  ...    0    0    0    0    0\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoXnd8RVz_fJ",
        "colab_type": "code",
        "outputId": "d389f6d2-5382-45d5-a0fd-ad160c55f373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "for i in range(1, 29):\n",
        "    func = lambda z: np.concatenate([preds[:, 30 + i], np.zeros(preds.shape[0], dtype='int')])\n",
        "    ss[[f'F{i}']] = ss[[f'F{i}']].apply(func, axis=0)\n",
        "ss.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>F5</th>\n",
              "      <th>F6</th>\n",
              "      <th>F7</th>\n",
              "      <th>F8</th>\n",
              "      <th>F9</th>\n",
              "      <th>F10</th>\n",
              "      <th>F11</th>\n",
              "      <th>F12</th>\n",
              "      <th>F13</th>\n",
              "      <th>F14</th>\n",
              "      <th>F15</th>\n",
              "      <th>F16</th>\n",
              "      <th>F17</th>\n",
              "      <th>F18</th>\n",
              "      <th>F19</th>\n",
              "      <th>F20</th>\n",
              "      <th>F21</th>\n",
              "      <th>F22</th>\n",
              "      <th>F23</th>\n",
              "      <th>F24</th>\n",
              "      <th>F25</th>\n",
              "      <th>F26</th>\n",
              "      <th>F27</th>\n",
              "      <th>F28</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              id  F1  F2  F3  F4  ...  F24  F25  F26  F27  F28\n",
              "0  HOBBIES_1_001_CA_1_validation   1   1   1   1  ...    1    1    1    1    1\n",
              "1  HOBBIES_1_002_CA_1_validation   0   0   0   0  ...    0    0    0    0    0\n",
              "2  HOBBIES_1_003_CA_1_validation   1   1   1   1  ...    1    1    1    1    1\n",
              "3  HOBBIES_1_004_CA_1_validation   2   2   2   2  ...    2    2    2    2    2\n",
              "4  HOBBIES_1_005_CA_1_validation   1   1   1   1  ...    2    2    2    2    2\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT1_OC9l_GQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### make length of each time series equal 720 ###\n",
        "time_series2 = []\n",
        "for i, ts in enumerate(time_series):\n",
        "    if len(ts) < 720:\n",
        "        time_series2.append(np.pad(ts, (720 - len(ts), 0), 'constant'))\n",
        "    else:\n",
        "        time_series2.append(ts[-720:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBzMccP-9QI_",
        "colab_type": "code",
        "outputId": "c73099e5-bd11-4e85-f5e4-ac1daf816426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "### generate embeddings for GNN training ###\n",
        "hiddens = np.zeros((720 - 31, len(time_series2), 16))\n",
        "for i in range(0, len(time_series2), 200):\n",
        "    batch = np.vstack(time_series2[i : i + 200])\n",
        "    hidd = []\n",
        "    for j in range(720 - 31):\n",
        "        batch_j = batch[:, j : j + 32]\n",
        "        batch_var = Variable(torch.from_numpy(batch_j).float()).to(device)\n",
        "        _, hidden = model_1(batch_var, future=0)\n",
        "        hidd.append(hidden[-1]) # hidden (list): 32 x (200, 16)\n",
        "    if i % 5000 == 0:\n",
        "        print('i =', i)\n",
        "    hidden = [hid.detach().cpu().numpy() for hid in hidd]\n",
        "    hiddens[:, i : i + 200, :] = np.stack(hidden, axis=0)\n",
        "\n",
        "batch = np.vstack(time_series2[-90:])\n",
        "hidd = []\n",
        "for j in range(720 - 31):\n",
        "    batch_j = batch[:, j : j + 32]\n",
        "    batch_var = Variable(torch.from_numpy(batch_j).float()).to(device)\n",
        "    _, hidden = model_1(batch_var, future=0)\n",
        "    hidd.append(hidden[-1]) # hidden (list): 32 x (200, 16)\n",
        "hidden = [hid.detach().cpu().numpy() for hid in hidd]\n",
        "hiddens[:, -90: , :] = np.stack(hidden, axis=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i = 0\n",
            "i = 5000\n",
            "i = 10000\n",
            "i = 15000\n",
            "i = 20000\n",
            "i = 25000\n",
            "i = 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1h0z_WfteDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('lstm_hidden_states.pickle', 'wb') as handle:\n",
        "    pickle.dump(hiddens, handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9LQNc_gL7t2",
        "colab_type": "code",
        "outputId": "0c411f9c-0af3-4482-9668-f487040a4cb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "### generate embeddings for GNN evaluation ###\n",
        "hiddens = np.zeros((28, len(time_series2), 16))\n",
        "for i in range(0, len(time_series2) - 200, 200):\n",
        "    batch = np.vstack(time_series2[i : i + 200])\n",
        "    hidd = []\n",
        "    y_preds = np.zeros((200, 28), dtype='int')\n",
        "    for j in range(28):\n",
        "        if j == 0:\n",
        "            batch_j = batch[:, -32:]\n",
        "        else:\n",
        "            batch_j = np.hstack([batch[:, -32 + j :], y_preds[:, :j]])\n",
        "        batch_var = Variable(torch.from_numpy(batch_j).float()).to(device)\n",
        "        y_pred, hidden = model_1(batch_var, future=0)\n",
        "        y_preds[:, j] = np.around(y_pred[:, -1].detach().cpu().numpy()).astype('int')\n",
        "        hidd.append(hidden[-1]) # hidden (list): 32 x (200, 16)\n",
        "    if i % 5000 == 0:\n",
        "        print('i =', i)\n",
        "    hidden = [hid.detach().cpu().numpy() for hid in hidd]\n",
        "    hiddens[:, i : i + 200, :] = np.stack(hidden, axis=0)\n",
        "\n",
        "batch = np.vstack(time_series2[-90:])\n",
        "hidd = []\n",
        "y_preds = np.zeros((90, 28), dtype='int')\n",
        "for j in range(28):\n",
        "    if j == 0:\n",
        "        batch_j = batch[:, -32:]\n",
        "    else:\n",
        "        batch_j = np.hstack([batch[:, -32 + j :], y_preds[:, :j]])\n",
        "    batch_var = Variable(torch.from_numpy(batch_j).float()).to(device)\n",
        "    y_pred, hidden = model_1(batch_var, future=0)\n",
        "    y_preds[:, j] = np.around(y_pred[:, -1].detach().cpu().numpy()).astype('int')\n",
        "    hidd.append(hidden[-1]) # hidden (list): 32 x (200, 16)\n",
        "hidden = [hid.detach().cpu().numpy() for hid in hidd]\n",
        "hiddens[:, -90:, :] = np.stack(hidden, axis=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i = 0\n",
            "i = 5000\n",
            "i = 10000\n",
            "i = 15000\n",
            "i = 20000\n",
            "i = 25000\n",
            "i = 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCpCmxowmpiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('lstm_hidden_states_val.pickle', 'wb') as handle:\n",
        "    pickle.dump(hiddens, handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8dgbKrX0kEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ss.to_csv('lstm_submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}